<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    
    <title>说话人分离并转录实战 | Hexo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    
      <link rel="icon" href="/favicon.png">
    

    
<link rel="stylesheet" href="/css/style.css">


    
<link rel="stylesheet" href="/js/google-code-prettify/tomorrow-night-eighties.min.css">


  <meta name="generator" content="Hexo 7.3.0"></head>

  <body>

<header>
	<a id="logo" href="/" title="Hexo">
	<img src="/favicon.png" alt="Hexo"></a>
	
	
		<!--搜索栏-->
		<i class="js-toggle-search iconfont icon-search"></i>


<form class="js-search search-form search-form--modal" method="get" action="http://gushi.li" role="search">
	<div class="search-form__inner">
		<div>
			<i class="iconfont icon-search"></i>
			<input class="text-input" placeholder="Enter Key..." type="search">
		</div>
	</div>
</form>
	

	
		<!--侧边导航栏-->
		<a id="nav-toggle" href="#"><span></span></a>

<nav>
	<div class="menu-top-container">
		<ul id="menu-top" class="menu">
			
				
				<li class="current-menu-item">
					<a href="http://weibo.com/" target="_blank">Weibo</a>
				</li>
			
		</ul>
	</div>
</nav>
	

</header>
<div class="m-header ">
	<section id="hero1" class="hero">
		<div class="inner">
		</div>
	</section>
	
		<figure class="top-image" data-enable=true></figure>
	
</div>

<!--文章列表-->
<div class="wrapper">
  
    <!--文章-->
<article>
	
  
    <h1 class="post-title" itemprop="name">
      说话人分离并转录实战
    </h1>
  

	<div class='post-body mb'>
		<h1 id="服务器部署-FastAPI-说话人分离应用完整指南"><a href="#服务器部署-FastAPI-说话人分离应用完整指南" class="headerlink" title="服务器部署 FastAPI 说话人分离应用完整指南"></a>服务器部署 FastAPI 说话人分离应用完整指南</h1><h6 id="本项目基于FunASR开源制作"><a href="#本项目基于FunASR开源制作" class="headerlink" title="本项目基于FunASR开源制作"></a>本项目基于<a target="_blank" rel="noopener" href="https://github.com/modelscope/FunASR">FunASR</a>开源制作</h6><p>##一、部署前准备</p>
<h3 id="​服务器环境要求"><a href="#​服务器环境要求" class="headerlink" title="​服务器环境要求"></a>​服务器环境要求</h3><p>Ubuntu 18.04   （也可本地部署成功后再部署到服务器重）<br>Python 3.8+<br>CUDA 11.8+（如需GPU加速）<br>至少 4GB 显存<br>存储空间：模型文件需预留 10GB+ 空间</p>
<h4 id="​目录结构"><a href="#​目录结构" class="headerlink" title="​目录结构"></a>​目录结构</h4><p>bash<br>&#x2F;project-root<br>├── app<br>│   ├── AudioSeparation.py<br>│   ├── main.py<br>│   ├── requirements.txt<br>├── models<br>│   ├── paraformer-zh<br>│   ├── speech_fsmn_vad_zh-cn-16k-common-pytorch<br>│   └── …<br>├── static<br>│   └── styles.css        # 示例CSS文件<br>├── templates<br>│   └── upload.html<br>└── logs                  # 日志目录</p>
<h2 id="二、AudioSeparationGUI（音频分离）"><a href="#二、AudioSeparationGUI（音频分离）" class="headerlink" title="二、AudioSeparationGUI（音频分离）"></a>二、AudioSeparationGUI（音频分离）</h2><p>  AudioSeparationGUI（音频分离），是实现多人对话（如电话、会议等情景）的音频分离，大家可以体验一下。<br>  <img src="/images/test" alt="测试音频转录"><br>上面的结果还处于测试阶段，我们实际使用的时候（或给别人使用的时候）往往需要一个前端界面去操控，这个时候我们采用一种FasterApi框架去完成前端交互的任务。<br>FastAPi是一个现代、快速（高性能）的python web框架，客户端通过GET、POST、PUT、DELETE等动作，对服务器端资源进行操作。通俗来说服务器部署后，用户可以通过浏览器进行资源的访问。<br>   我在部署前端界面增添了一些功能：<br>     增添了前端可视化界面<br>     增添了用户选择音频文件的可视化界面<br>     增添了批量上传音频的功能<br>     增添了下载后默认保存到浏览器下载路径，以便用户寻找转录结果<br> <img src="/images/test" alt="测试音频转录"><br> <img src="/images/test" alt="测试音频转录"><br> ##三、部署</p>
<h3 id="1-相关依赖下载"><a href="#1-相关依赖下载" class="headerlink" title="1.相关依赖下载"></a>1.相关依赖下载</h3><p>根据requirements.txt提供的依赖下载<br>（最好先创建一个虚拟环境或者用conda）<br>  执行命令：<code>pip install requirements</code></p>
<h4 id="requirements-txt"><a href="#requirements-txt" class="headerlink" title="requirements.txt"></a>requirements.txt</h4><ul>
<li>torchvision</li>
<li>fastapi</li>
<li>uvicorn</li>
<li>torchaudio</li>
<li>funasr&#x3D;&#x3D;1.2.0</li>
<li>modelscope</li>
<li>huggingface</li>
<li>huggingface_hub</li>
<li>pydub</li>
<li>onnx</li>
<li>onnxconverter-common</li>
<li>ffmpeg-python</li>
</ul>
<h3 id="2-相关模型的下载"><a href="#2-相关模型的下载" class="headerlink" title="2.相关模型的下载"></a>2.相关模型的下载</h3><h4 id="modelscope（魔塔社区中下载）"><a href="#modelscope（魔塔社区中下载）" class="headerlink" title="modelscope（魔塔社区中下载）"></a>modelscope（魔塔社区中下载）</h4><ul>
<li>speech_campplus_sv_zh-cn_16k-common</li>
<li>speech_fsmn_vad_zh-cn-16k-common-pytorch</li>
<li>speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch</li>
<li>punc_ct-transformer_zh-cn-common-vocab272727-pytorch</li>
</ul>
<p>##四、程序<br><em>注意：因为 FastAPI 尝试挂载一个静态文件目录 (static)，但是该目录在项目中并不存在。你有两个选择来修复这个问题：如果你暂时不需要静态文件，可以在其中放一个空文件（比如 .gitkeep 或 README.md），以便 FastAPI 能正常启动。这边采用放置空文件来解决的。</em><br>###1.AudioSeparation.py</p>
<h5 id="import-os"><a href="#import-os" class="headerlink" title="import os"></a>import os</h5><p>#####import ffmpeg<br>#####import torch<br>#####from datetime import timedelta<br>#####from funasr import AutoModel</p>
<p>#####def format_time(milliseconds):<br>    ##格式化时间，超过1小时显示hh:mm:ss.mmm，否则显示mm:ss.mmm<br>    time_obj &#x3D; timedelta(milliseconds&#x3D;milliseconds)<br>    hours &#x3D; time_obj.seconds &#x2F;&#x2F; 3600<br>    minutes &#x3D; (time_obj.seconds % 3600) &#x2F;&#x2F; 60<br>    seconds &#x3D; time_obj.seconds % 60<br>    milliseconds &#x3D; milliseconds % 1000</p>
<pre><code>if hours &gt; 0:
    return f&quot;&#123;hours:02d&#125;:&#123;minutes:02d&#125;:&#123;seconds:02d&#125;.&#123;milliseconds:03d&#125;&quot;
return f&quot;&#123;minutes:02d&#125;:&#123;seconds:02d&#125;.&#123;milliseconds:03d&#125;&quot;
</code></pre>
<p>#####def audio_speaker_separation(input_audio_path, output_dir):<br>    ##处理音频文件，生成转录文本并保存到txt文件中<br>    Args:<br>        input_audio_path (str): 输入音频路径<br>        output_dir (str): 输出文件夹路径<br>    Returns:<br>        str: 保存的转录文件路径<br>    # 硬编码模型路径（大家在使用时要修改其路径）<br>    asr_model_path &#x3D; “&#x2F;home&#x2F;data&#x2F;data&#x2F;iic&#x2F;paraformer-zh”<br>    asr_model_revision &#x3D; “v2.0.4”<br>    vad_model_path &#x3D; “&#x2F;home&#x2F;data&#x2F;jdssy_liy&#x2F;Speaker Diarization&#x2F;speech_fsmn_vad_zh-cn-16k-common-pytorch”<br>    vad_model_revision &#x3D; “v2.0.4”<br>    punc_model_path &#x3D; “&#x2F;home&#x2F;data&#x2F;data&#x2F;iic&#x2F;punc_ct-transformer_zh-cn-common-vocab272727-pytorch”<br>    punc_model_revision &#x3D; “v2.0.4”<br>    spk_model_path &#x3D; “&#x2F;home&#x2F;data&#x2F;jdssy_liy&#x2F;Speaker Diarization&#x2F;speech_campplus_sv_zh-cn_16k-common”<br>    spk_model_revision &#x3D; “v2.0.4”<br>    device &#x3D; “cuda” if torch.cuda.is_available() else “cpu”</p>
<pre><code># 初始化模型
try:
    model = AutoModel(
        model=asr_model_path,
        model_revision=asr_model_revision,
        vad_model=vad_model_path,
        vad_model_revision=vad_model_revision,
        punc_model=punc_model_path,
        punc_model_revision=punc_model_revision,
        spk_model=spk_model_path,
        spk_model_revision=spk_model_revision,
        ngpu=1 if torch.cuda.is_available() else 0,
        device=device,
    )
except Exception as e:
    raise RuntimeError(f&quot;Model initialization failed: &#123;str(e)&#125;&quot;)

# 检查输入音频文件是否存在
if not os.path.exists(input_audio_path):
    raise FileNotFoundError(f&quot;Audio file not found: &#123;input_audio_path&#125;&quot;)

# 确保输出目录存在
os.makedirs(output_dir, exist_ok=True)
output_file = os.path.join(output_dir, os.path.basename(input_audio_path) + &quot;_transcription.txt&quot;)

try:
    # 使用 ffmpeg 将音频转为16kHz单声道PCM
    audio_bytes, _ = (
        ffmpeg.input(input_audio_path, threads=0)
        .output(&quot;-&quot;, format=&quot;s16le&quot;, acodec=&quot;pcm_s16le&quot;, ac=1, ar=16000)
        .run(capture_stdout=True, capture_stderr=True)
    )

    # 调用模型生成转录结果
    res = model.generate(input=audio_bytes, batch_size_s=300, is_final=True, sentence_timestamp=True)

    # 解析转录结果并生成输出文本
    transcription = &quot;\n&quot;.join(
        f&quot;&#123;format_time(sentence[&#39;start&#39;])&#125; - &#123;format_time(sentence[&#39;end&#39;])&#125; 说话人&#123;sentence[&#39;spk&#39;]&#125;: &#123;sentence[&#39;text&#39;]&#125;&quot;
        for sentence in res[0][&quot;sentence_info&quot;]
    )

    # 将转录结果保存到文本文件中
    with open(output_file, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f:
        f.write(transcription)

    print(f&quot;Transcription saved to &#123;output_file&#125;&quot;)
    return output_file
except Exception as e:
    raise RuntimeError(f&quot;Audio processing failed: &#123;str(e)&#125;&quot;)
</code></pre>
<p>​<br>###2.main.py<br>####fasterapi应用实现的主程序</p>
<pre><code class="python">import os
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.templating import Jinja2Templates
from fastapi.staticfiles import StaticFiles
from starlette.requests import Request
from AudioSeparation import audio_speaker_separation  # 导入你已经写好的音频处理逻辑

app = FastAPI()

templates = Jinja2Templates(directory=&quot;templates&quot;)
app.mount(&quot;/static&quot;, StaticFiles(directory=&quot;static&quot;), name=&quot;static&quot;)

UPLOAD_FOLDER = &quot;uploaded_files&quot;
OUTPUT_FOLDER = &quot;output_files&quot;

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

@app.get(&quot;/&quot;, response_class=HTMLResponse)
async def home(request: Request):
    &quot;&quot;&quot;返回上传文件的HTML页面&quot;&quot;&quot;
    return templates.TemplateResponse(&quot;upload.html&quot;, &#123;&quot;request&quot;: request&#125;)


@app.post(&quot;/process-audio/&quot;)
async def process_audio(files: list[UploadFile] = File(...)):
    &quot;&quot;&quot;处理上传的音频文件&quot;&quot;&quot;
    try:
        download_links = []
        for file in files:
            # 保存上传的文件
            file_path = os.path.join(UPLOAD_FOLDER, file.filename)
            with open(file_path, &quot;wb&quot;) as f:
                f.write(await file.read())

            # 调用音频分离和转录函数
            try:
                output_file = audio_speaker_separation(file_path, OUTPUT_FOLDER)
                download_link = f&quot;/download/&#123;os.path.basename(output_file)&#125;&quot;
                download_links.append(download_link)

                # 删除上传的临时文件
                if os.path.exists(file_path):
                    os.remove(file_path)

            except Exception as e:
                # 如果处理失败，也删除上传的文件
                if os.path.exists(file_path):
                    os.remove(file_path)
                raise HTTPException(status_code=500, detail=f&quot;Error processing &#123;file.filename&#125;: &#123;str(e)&#125;&quot;)

        return &#123;&quot;message&quot;: &quot;Files processed successfully&quot;, &quot;download_links&quot;: download_links&#125;
    except Exception as e:
        raise HTTPException(status_code=500, detail=f&quot;An error occurred: &#123;str(e)&#125;&quot;)
@app.get(&quot;/download/&#123;file_name&#125;&quot;)
async def download_file(file_name: str):
    &quot;&quot;&quot;下载处理后的文本文件&quot;&quot;&quot;
    file_path = os.path.join(OUTPUT_FOLDER, file_name)
    if os.path.exists(file_path):
        return FileResponse(
            file_path,
            media_type=&#39;application/octet-stream&#39;,
            filename=file_name
        )
    raise HTTPException(status_code=404, detail=&quot;File not found&quot;)```


###3.upload.html
####前端网页文件
```html
&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width, initial-scale=1.0&quot;&gt;
    &lt;title&gt;Audio Processing&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;h1&gt;Upload Your Audio Files&lt;/h1&gt;
    &lt;form id=&quot;uploadForm&quot; action=&quot;/process-audio/&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt;
        &lt;label for=&quot;files&quot;&gt;选择文件:&lt;/label&gt;
        &lt;input type=&quot;file&quot; id=&quot;files&quot; name=&quot;files&quot; multiple&gt;
        &lt;button type=&quot;submit&quot;&gt;Upload and Process&lt;/button&gt;
    &lt;/form&gt;
    &lt;div id=&quot;loading&quot; style=&quot;display: none;&quot;&gt;正在运行中，请等待...&lt;/div&gt;

    &lt;script&gt;
    const form = document.getElementById(&#39;uploadForm&#39;);
    const loading = document.getElementById(&#39;loading&#39;);

    form.addEventListener(&#39;submit&#39;, async (event) =&gt; &#123;
        event.preventDefault();
        loading.style.display = &#39;block&#39;;

        const formData = new FormData(form);
        const response = await fetch(&#39;/process-audio/&#39;, &#123;
            method: &#39;POST&#39;,
            body: formData
        &#125;);

        const data = await response.json();
        loading.style.display = &#39;none&#39;;

        if (data.download_links) &#123;
            data.download_links.forEach(link =&gt; &#123;
                const a = document.createElement(&#39;a&#39;);
                a.href = link;
                a.download = link.split(&#39;/&#39;).pop();
                a.click();
            &#125;);
        &#125; else &#123;
            alert(&#39;处理文件时出错！&#39;);
        &#125;
    &#125;);
&lt;/script&gt;

&lt;/body&gt;
&lt;/html&gt;```

##五、服务器部署
   ####登录服务器界面后   创建虚拟环境
   ####下载好相关依赖
   ####下载好相关模型
   ####运行即可
以下是服务器使用步骤：
1.启动前移动到该路径下     cd /home/data/jdssy_liy/Speaker\ Diarization
2.进入虚拟环境    source /home/data/jdssy_liy/my_venv/bin/activate
3.启动该程序   uvicorn main:app --host 0.0.0.0 --port 8090运行命令
4.使用结束后退出该环境   deactivate 
以上是我在服务器部署的命令，大家可以根据自己调整，运行后输入服务器公网IP+端口即可访问
</code></pre>

	</div>
	<div class="meta split">
		
			<span>本文总阅读量 <span id="busuanzi_value_page_pv"></span> 次</span>
		
		<time class="post-date" datetime="2024-02-27T06:30:00.000Z" itemprop="datePublished">2024-02-27</time>
	</div>
</article>

<!--评论-->


  
</div>


  <svg id="bigTriangleColor" width="100%" height="40" viewBox="0 0 100 102" preserveAspectRatio="none">
    <path d="M0 0 L50 100 L100 0 Z"></path>
  </svg>

  


  <div class="wrapper"></div>





<div class="fat-footer">
	<div class="wrapper">
		<div class="layout layout--center">
			<div class="layout__item palm-mb">
				<div class="media">
					<img class="headimg" src='https://imgchr.github.la/steve.jpeg author info' alt='John Doe'>
					<div class="media__body">
						<h4>justpsvm</h4>
						<p class='site-description'>唯一不变的就是在变.</p>
					</div>
				</div>
				<div class="author-contact">
					<ul>
						
							
							<li>
				        		<a href="http://weibo.com/" target="_blank">
				        			
				        				<i class="iconfont icon-weibo"></i>
				        			
				        		</a>
				        	</li>
						
							
							<li>
				        		<a href="https://github.com/" target="_blank">
				        			
				        				<i class="iconfont icon-github"></i>
				        			
				        		</a>
				        	</li>
						
							
							<li>
				        		<a href="https://www.zhihu.com/" target="_blank">
				        			
										<i class="iconfont icon-zhihu"></i>
				        			
				        		</a>
				        	</li>
						
					</ul>
				</div>
			</div>
		</div>
	</div>
</div>

<footer class="footer" role="contentinfo">
	<div class="wrapper wrapper--wide split split--responsive">
		
			<span>本站总访问量 <span id="busuanzi_value_site_pv"></span> 次, 访客数 <span id="busuanzi_value_site_uv"></span> 人次</span>
		
		<span>Theme by <a target="_blank" rel="noopener" href="http://github.com/justpsvm">justpsvm</a>. Powered by <a target="_blank" rel="noopener" href="http://hexo.io">Hexo</a></span>
	</div>
</footer>

	<!-－这里导入了 lib.js 里面涵盖了 jQuery 等框架 所以注释掉-->
	<!--
<script src="http://lib.sinaapp.com/js/jquery/2.0/jquery.min.js"></script>
-->
	
<script src="/js/lib.js"></script>

	
<script src="/js/google-code-prettify/prettify.js"></script>

	
<script src="/js/module.js"></script>

	
<script src="/js/script.js"></script>

	
		<script async src="http://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
	
	<script type='text/javascript'>
		//代码高亮
		$(document).ready(function(){
	 		$('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
   			prettyPrint();
		});
	</script>
	</body>
</html>
