<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>说话人分离并转录实战</title>
      <link href="/2024/02/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/"/>
      <url>/2024/02/27/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9C%A8%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="服务器部署-FastAPI-说话人分离应用完整指南"><a href="#服务器部署-FastAPI-说话人分离应用完整指南" class="headerlink" title="服务器部署 FastAPI 说话人分离应用完整指南"></a>服务器部署 FastAPI 说话人分离应用完整指南</h1><h3 id="本项目基于FunASR开源制作"><a href="#本项目基于FunASR开源制作" class="headerlink" title="本项目基于FunASR开源制作"></a>本项目基于<a href="https://github.com/modelscope/FunASR">FunASR</a>开源制作</h3><h2 id="1-部署前准备"><a href="#1-部署前准备" class="headerlink" title="1.部署前准备"></a>1.部署前准备</h2><h2 id="1-1​服务器环境要求"><a href="#1-1​服务器环境要求" class="headerlink" title="1.1​服务器环境要求"></a>1.1​服务器环境要求</h2><p>Ubuntu 18.04   （也可本地部署成功后再部署到服务器重）<br>Python 3.8+<br>CUDA 11.8+（如需GPU加速）<br>至少 4GB 显存<br>存储空间：模型文件需预留 10GB+ 空间</p><h2 id="1-2​目录结构"><a href="#1-2​目录结构" class="headerlink" title="1.2​目录结构"></a>1.2​目录结构</h2><p><strong>bash<br>&#x2F;project-root<br>├── app<br>│   ├── AudioSeparation.py<br>│   ├── main.py<br>│   ├── requirements.txt<br>├── models<br>│   ├── paraformer-zh<br>│   ├── speech_fsmn_vad_zh-cn-16k-common-pytorch<br>│   └── …<br>├── static<br>│   └── styles.css        # 示例CSS文件<br>├── templates<br>│   └── upload.html<br>└── logs                  # 日志目录</strong></p><h2 id="2-AudioSeparationGUI（音频分离）"><a href="#2-AudioSeparationGUI（音频分离）" class="headerlink" title="2.AudioSeparationGUI（音频分离）"></a>2.AudioSeparationGUI（音频分离）</h2><pre><code>AudioSeparationGUI（音频分离），是实现多人对话（如电话、会议等情景）的音频分离，大家可以体验一下。</code></pre><p>  <img src="/images/test.jpg" alt="测试音频转录"><br>    上面的结果还处于测试阶段，我们实际使用的时候（或给别人使用的时候）往往需要一个前端界面去操控，这个时候我们采用一种FasterApi框架去完成前端交互的任务。<br>    FastAPi是一个现代、快速（高性能）的python web框架，客户端通过GET、POST、PUT、DELETE等动作，对服务器端资源进行操作。通俗来说服务器部署后，用户可以通过浏览器进行资源的访问。<br>   我在部署前端界面增添了一些功能：<br>     增添了前端可视化界面<br>     增添了用户选择音频文件的可视化界面<br>     增添了批量上传音频的功能<br>     增添了下载后默认保存到浏览器下载路径，以便用户寻找转录结果<br> <img src="/images/show1.jpg" alt="测试音频转录"><br> <img src="/images/show2.jpg" alt="测试音频转录"></p><h2 id="3-部署"><a href="#3-部署" class="headerlink" title="3.部署"></a>3.部署</h2><h2 id="3-1相关依赖下载"><a href="#3-1相关依赖下载" class="headerlink" title="3.1相关依赖下载"></a>3.1相关依赖下载</h2><pre><code>根据requirements.txt提供的依赖下载</code></pre><p><em>（最好先创建一个虚拟环境或者用conda）</em><br>  <strong>执行命令</strong>：<code>pip install requirements</code></p><h3 id="requirements-txt"><a href="#requirements-txt" class="headerlink" title="requirements.txt"></a>requirements.txt</h3>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">torchvision<br>fastapi<br>uvicorn<br>torchaudio  <br>funasr==1.2.0  <br>modelscope  <br>huggingface<br>huggingface_hub<br>pydub<br>onnx<br>onnxconverter-common<br>ffmpeg-python<br></code></pre></td></tr></table></figure><h2 id="3-2相关模型的下载"><a href="#3-2相关模型的下载" class="headerlink" title="3.2相关模型的下载"></a>3.2相关模型的下载</h2><h3 id="modelscope（魔塔社区中下载）"><a href="#modelscope（魔塔社区中下载）" class="headerlink" title="modelscope（魔塔社区中下载）"></a>modelscope（魔塔社区中下载）</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs plaintext">speech_campplus_sv_zh-cn_16k-common<br>speech_fsmn_vad_zh-cn-16k-common-pytorch<br>speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch<br>punc_ct-transformer_zh-cn-common-vocab272727-pytorch<br></code></pre></td></tr></table></figure><h2 id="4-程序"><a href="#4-程序" class="headerlink" title="4.程序"></a>4.程序</h2><pre><code> **详细程序到我的github仓库查询** 地址：</code></pre><h2 id="5-服务器部署"><a href="#5-服务器部署" class="headerlink" title="5.服务器部署"></a>5.服务器部署</h2><h3 id="登录服务器界面后-创建虚拟环境"><a href="#登录服务器界面后-创建虚拟环境" class="headerlink" title="登录服务器界面后   创建虚拟环境"></a>登录服务器界面后   创建虚拟环境</h3><h3 id="下载好相关依赖"><a href="#下载好相关依赖" class="headerlink" title="下载好相关依赖"></a>下载好相关依赖</h3><h3 id="下载好相关模型"><a href="#下载好相关模型" class="headerlink" title="下载好相关模型"></a>下载好相关模型</h3><h3 id="运行即可"><a href="#运行即可" class="headerlink" title="运行即可"></a>运行即可</h3><p><strong>以下是服务器使用步骤：<br>1.启动前移动到该路径下     cd &#x2F;home&#x2F;data&#x2F;jdssy_liy&#x2F;Speaker\ Diarization（以我使用的服务器为例）<br>2.进入虚拟环境    source &#x2F;home&#x2F;data&#x2F;jdssy_liy&#x2F;my_venv&#x2F;bin&#x2F;activate<br>3.启动该程序   uvicorn main:app –host 0.0.0.0 –port 8090运行命令<br>4.使用结束后退出该环境   deactivate<br>以上是我在服务器部署的命令，大家可以根据自己调整，运行后输入服务器公网IP+端口即可访问</strong></p>]]></content>
      
      
      <categories>
          
          <category> AI实战 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
            <tag> 语音识别 </tag>
            
            <tag> Pytorch </tag>
            
        </tags>
      
    </entry>
    
    
  
  
    
  
</search>
